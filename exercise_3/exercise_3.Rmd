---
title: "Jayme_Blake_Exercise3"
author: "Jayme Gerring and Blake (Pin-Yun) Lin"
date: "3/24/2022"
output: md_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

## hint r script: glass, tree_example, random_forest, hockey

library(tidyverse)
library(rpart)
library(rpart.plot)
library(rsample) 
library(rsample) 
library(randomForest)
library(lubridate)
library(modelr)
library(gbm)


greenbuildings = read.csv("~/Documents/GitHub/ECO395M/data/greenbuildings.csv", header=TRUE)
CAhousing = read.csv("~/Documents/GitHub/ECO395M/data/CAhousing.csv", header=TRUE)
dengue = read.csv("~/Documents/MA Courses/Data Mining/Stats-Learning/exercise_3/data/dengue.csv", header=TRUE)

```
## Problem 1: What Causes What?

1. There's a causality problem, it's hard to come to a clear conclusion just by looking at police force size. Cities with higher than average crime rate might hire more police than an average city, this might lead to a false conclusion that police are ineffective at solving crime. On the other hand, having more police means that crime gets more easily detected, this might lead someone to conclude crime rates are higher when in fact that might be the same as any other city with a smaller police force. Simply put, it's hard to conclude what effect increased policing has on crime. 

2. Basically, the researchers added an IV variable by using the terror alert system. High Terror alert means that there will be an increased police presence regardless of the amount of crime that's happening in a given area. In their first regression they found that a high terror alert is predicted to lower the number of crime by about 7 crimes. In the second regression, controlling for metro ridership, the high terror alert is predicted to lower the crime rate by about 6 crimes.\

3. The researchers decided to control for metro ridership to make sure that the lower crime rate caused by the high terror rate wasn't simply a matter of a smaller amount of people being out and about on the street. The researchers were trying to capture the effect that a high terror rate could have on the amount of people in the city. 

4. The first column comprises of a linear model using robust regression with three coefficients. One of the coefficients looks at the effect of a high terror rate solely within the first police district area, meaning the national mall. This is because if terrorists were to attack Washington, D.C. they would probably focus on this area. The next coefficient is the effect of the high alert on the rest of the police district areas within DC. The third coefficient is the log of midday metro ridership. Basically this regression is showing that the high alert (and therefore an increased number of police) lowers crime mostly in the National Mall area, the effect in the rest of the city isn't as profound as it is in the other area, even though it still lowers crime by a small amount. However, the regression still shows strong evidence that more police lowers crime, this is because during a high alert the DC police force is probably going to increase police the most in district one. 

## Problem 2 Tree Modeling: Dengue Cases
### Part 1: CART

```{r 2, message=FALSE, echo=FALSE}

#fixing na values 
dengue <- na.exclude(dengue)
dengue$city = dengue$city %>% factor()
dengue$season = dengue$season %>% factor()

#create a testing and training set
dengue_split = initial_split(dengue, prop = 0.9)
dengue_train = training(dengue_split)
dengue_test = testing(dengue_split)

#creating the tree, CART model

dengue_tree = rpart(total_cases ~ ., data = dengue_train,
                    control = rpart.control(cp = 0.002, minsplit=30))

rpart.plot(dengue_tree, digits=-5, type=4, extra=1)
```

The model above shows the un-pruned CART Tree, we will proceed to prune and then calculate RMSE.


``` {r 2 cont , message=FALSE, echo=FALSE}
# this function actually prunes the tree at that level
prune_1se = function(my_tree) {
  out = as.data.frame(my_tree$cptable)
  thresh = min(out$xerror + out$xstd)
  cp_opt = max(out$CP[out$xerror <= thresh])
  prune(my_tree, cp=cp_opt)
}

#lets prune to make sure we have the best model
prune_dengue_tree = prune_1se(dengue_tree)

#checking
rmse_CART = rmse(prune_dengue_tree, dengue_test)

cat(rmse_CART,' RMSE for Pruned CART Model') 

```

### Part 2: Random Forest
``` {r 2 cont again , message=FALSE, echo=FALSE}
#random forest

DengueRandom = randomForest(total_cases ~ ., data= dengue_train, importance = TRUE)

plot(DengueRandom)


```

This plot shows the out of bag MSE as a function of the number of trees used. Let's proceed to look at the RMSE compared to the testing set.


``` {r 2 random conclusion, message=FALSE, echo=FALSE}

rmse_random = rmse(DengueRandom, dengue_test)

cat(rmse_random,' RMSE for Random Forest')
```

### Part 3: Gradient Boosted Trees

``` {r 2 boosted , message=FALSE, echo=FALSE}

#boosted trees
DengueBoost = gbm(total_cases ~ ., data= dengue_train,
             interaction.depth=4, n.trees=350, shrinkage=.05, cv.folds = 10, 
             distribution='gaussian')

gbm.perf(DengueBoost)

```

This plot shows the error curve of the Gradient Boosted Model, with the optimal number of trees listed as output. Let's now check the RMSE for the Gradient Boosted Trees Model. 


``` {r 2 boosted conclusion, message=FALSE, echo=FALSE}

#checking
rmse_boosted = rmse(DengueBoost, dengue_test) 

cat(rmse_boosted,' RMSE for Gradient Boosted Trees') 

```

Looking at the RMSE results from the three models, it appears that random forest would be the best choice for this particular set of data. The next section shows the partial dependency plots for the Random Forest Model. 

### Part 4: Partial Dependency Plots
``` {r 2 PD plots, message=FALSE, echo=FALSE}
#pd plots
partialPlot(DengueRandom, dengue_test, 'specific_humidity', las=1)

partialPlot(DengueRandom, dengue_test, 'precipitation_amt', las=1)

partialPlot(DengueRandom, dengue_test, 'tdtr_k', las=1)
```

### Wrap Up: 

Looking at the PD plots, most seem to make sense in the context of the science of mosquito breeding. Mosquitos require standing water in order to make baby mosquitos, it makes sense that as precipitation increases, the number of mosquitos increases, the increased number of mosquitos leads to more cases of Dengue. The same seems to be true of humidity. Humidity is a measure of how much evaporated moisture there is in the air, higher humidity would seem to indicate that there is a higher amount of water on the ground, and thus the amount of mosquito breeding grounds. Our wild card PD plot looks at the Average Diurnal Temperature Range. It shows that as DTR increases, the amount of predicted Dengue cases decreases. This makes sense as well, it's possible that temperature shocks kill mosquitos which leads to less Dengue cases. 






## Problem 3 Predictive model building: green certification
```{r Q3 CART}

# create the revenue per per square foot variable 
greenbuildings = mutate(greenbuildings, revenue = Rent * leasing_rate)

# split data into training and testing
set.seed(100)
green_split =  initial_split(greenbuildings, prop=0.8)
green_train = training(green_split)
green_test  = testing(green_split)

# let's fit a single tree
green.tree = rpart(revenue ~ . - LEED - Energystar - cd_total_07 - hd_total07 - leasing_rate - Rent, data=greenbuildings, control = rpart.control(cp = 0.00001), na.action=na.omit)
```




```{r Q3 random forest}

# now a random forest
# notice: no tuning parameters!  just using the default
# downside: takes longer because we're fitting hundreds of trees (500 by default)
# the importance=TRUE flag tells randomForest to calculate variable importance metrics
green.forest = randomForest(revenue ~ . - LEED - Energystar - cd_total_07 - hd_total07- leasing_rate - Rent, data=greenbuildings, na.action=na.omit, importance = TRUE)


# boosting 
green.boost = gbm(revenue ~ . - LEED - Energystar - cd_total_07 - hd_total07- leasing_rate - Rent, data=greenbuildings, interaction.depth=5, n.trees=500, shrinkage=.05)

# compare RMSE 
rmse(green.tree, green_test)
rmse(green.forest, green_test) 
rmse(green.boost, green_test) 


# details of Random forest
# shows out-of-bag MSE as a function of the number of trees used
plot(green.forest)

# variable importance measures
# how much does mean-squared error increase when we ignore a variable?
vi = varImpPlot(green.forest, type=1)

# partial dependence plots
# these are trying to isolate the partial effect of specific features
# on the outcome
partialPlot(green.forest, green_test, 'green_rating', las=1)

```



```{r Q4}
# PLOT1 original data
ggplot(CAhousing) + 
  geom_point(aes(x=longitude, y=latitude, color=medianHouseValue)) + 
  scale_color_continuous(type = "viridis")

# choose the best model  
# split data into training and testing:    
set.seed(101)
ca_split =  initial_split(CAhousing, prop=0.8)
ca_train = training(ca_split)
ca_test  = testing(ca_split)

# fit a single tree
ca.tree = rpart(medianHouseValue ~ . , data=CAhousing, control = rpart.control(cp = 0.00001))

# random forest 
ca.forest = randomForest(medianHouseValue ~ . , data=CAhousing, control = rpart.control(cp = 0.00001), importance=TRUE)

# boosting 
ca.boost = gbm(medianHouseValue ~ ., data = ca_train ,interaction.depth=5, n.trees=800, shrinkage=.25)

# OPTIONAL: tuning, how to choose # of trees and shrinkage, explaining?
gbm.perf(ca.boost)
yhat_test_gbm = predict(ca.boost, ca_test, n.trees=350)


# the model we choose here is: random forest for now 
rmse(ca.tree, ca_test)
rmse(ca.forest, ca_test)
rmse(ca.boost, ca_test)

# PLOT2: prediction 
CAhousing = CAhousing %>%
  mutate(ca_pred = predict(ca.forest, ca_test))

ggplot(CAhousing) + 
  geom_point(aes(x=longitude, y=latitude, color=ca_pred)) + 
  scale_color_continuous(type = "viridis")

# PLOT3: residual
CAhousing = CAhousing %>%
  mutate(ca_resid = sqrt((medianHouseValue-ca_pred)^2))

ggplot(CAhousing) + 
  geom_point(aes(x=longitude, y=latitude, color=ca_resid)) + 
  scale_color_continuous(type = "viridis")+
  labs(title = "Residuals versus longitude and latitude")+
  theme(plot.title = element_text(hjust = 0.5, face = "bold"))+
  guides(color = guide_legend(title="Residual"))

```

